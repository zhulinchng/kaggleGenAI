# Day 1 Quiz

## Which Gemini configuration setting controls the degree of randomness in the selection of the next predicted token?

- **Temperature**
- Top-K
- Top-P
- Output Token Count

## Which of the following is not a technique used to accelerate inference in large language models (LLMs)?

- Quantization
- Distillation
- Flash Attention
- **Fine-Tuning**

## Which of the following is a unique characteristic of the Gemini family of large language models (LLMs)?

- Gemini models were the first to introduce the concept of unsupervised pre-training.
- Gemini models can support multimodal inputs.
- Gemini models are decoder-only.
- **Gemini models can support a context window of up to 2M tokens.**

## How does Reinforcement Learning from Human Feedback (RLHF) improve large language models?

- By training the model on a massive dataset of unlabeled text.
- **By using a reward model to incentivize the generation of human-preferred responses.**
- By reducing the number of parameters in the model for faster inference.
- By converting the model into a recurrent neural network for improved performance.

## Which technique enhances an LLM's reasoning abilities by prompting it to produce intermediate reasoning steps, leading to more accurate answers?

- Zero-Shot Prompting
- Step-Back Prompting
- Self-Consistent Prompting
- **Chain-of-Thought Prompting**

## What is minimum GPU memory needed for inference on a 3B parameter model using standard float precision?

- 3GB
- 6GB
- **12GB**
- 24GB
