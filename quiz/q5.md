# Day 5 Quiz

## Which of these is not a core practice of MLOps for generative AI applications, as discussed in the whitepaper?

- Prompt engineering and evaluation as an iterative cycle.
- Data validation, model evaluation, and model monitoring.
- **Training a foundation model from scratch.**
- Managing and versioning prompt templates, chain definitions, and external datasets.

## What is a prompt template, in the context of generative AI?

- A simple text input from the user.
- **A set of instructions and examples with placeholders for user input.**
- The foundation model itself.
- The final output generated by the model.

## What is the purpose of chaining in generative AI applications?

- To maintain recency in the model's outputs.
- **To avoid hallucination and maintain recency in the model's outputs.**
- To increase the complexity of the model.
- To reduce the efficiency of the model.

## Why is evaluation a crucial step in the development of generative AI systems?

- To ensure the model is deployed to the correct infrastructure.
- To optimize resource utilization and reduce latency.
- To track the lineage of data and model versions.
- **To measure the quality and effectiveness of the model's outputs.**

## Which Vertex AI product allows for recurrent execution of evaluation jobs in production, skew, and drift detection processes?

- Vertex AI Model Monitoring.
- **Vertex AI Pipelines.**
- Vertex AI Feature Store.
- Vertex AI Model Registry.
